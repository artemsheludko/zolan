---
layout: post
comments: true
title: Installation de Kafka avec l opÃ©rateur Strimzi sur Kubernetes
tags: [kubernetes, kafka, strimzi, helm]
image: /post/2020/03/2020-03-30-installation-kafka-strimzi-kubernetes.png
---

Dans cet article nous allons dÃ©tailler l'installation de l'application Kafka a l'aide de l'[opÃ©rateur Strimzi](https://strimzi.io/). En effet, avec l'arrivÃ©e de plus en plus rÃ©guliÃ¨re d'application Cloud Native, les experts Dev/Ops sont de plus en plus amenÃ©s Ã  dÃ©ployer Kafka afin d'assurer la communication entre les diffÃ©rentes API. Le faire dans un contexte Kubernetes est de plus en plus rÃ©gulier. Nous allons donc dÃ©ployer, Ã  l'aide de l'outil [Helm3](https://helm.sh/), un cluster Kafka au sein d'un cluster Kubernetes [K3d](https://k3d.io/).

## Qu'est-ce que Strimzi

Strimzi fournit le moyen d'exÃ©cuter un cluster Apache Kafka sur Kubernetes dans diverses configurations de dÃ©ploiement. Pour le dÃ©veloppement, il est facile de configurer un cluster dans K3d par exemple en quelques minutes. Pour la production, vous pouvez personnaliser le cluster en fonction de vos besoins, en utilisant des fonctionnalitÃ©s telles que le rack awarness pour rÃ©partir les brokers Kafka entre diffÃ©rentes zones de disponibilitÃ©, et les fonctionnalitÃ©s de "Taints and Tolerations" pour exÃ©cuter Kafka sur des nÅ“uds dÃ©diÃ©s de votre cluster Kubernetes. Vous pouvez exposer Kafka en dehors de Kubernetes Ã  l'aide de NodePort, Load Balancer, Ingress et/ou des routes OpenShift, selon de vos besoins, et ceux-ci sont facilement sÃ©curisÃ©s Ã  l'aide de TLS.

La gestion native de Kafka ne se limite pas au broker. Vous pouvez Ã©galement gÃ©rer les topics Kafka, les utilisateurs, Kafka MirrorMaker et Kafka Connect Ã  l'aide de ressources personnalisÃ©es. Cela signifie que vous pouvez utiliser vos processus et outils Kubernetes familiers pour gÃ©rer des applications Kafka complÃ¨tes.

Utiliser Strimzi c'est aussi bÃ©nÃ©ficier d'un ensemble de Chart qui vous permette, via Helm de manager vos ressources Kafka.

## Objectif du tutoriel

Dans le cadre de cet article nous allons dÃ©ployer un cluster Kafka, Kafka bridge et un topic nommÃ© `TopicTest` dans un cluster Kubernetes au sein d'un namespace que nous allons nommer `Kafka`. L'ensemble de ces Ã©lÃ©ments sera crÃ©Ã© Ã  l'aide du dÃ©ploiement d'un chart Helm qui de faÃ§on sous-jacente utilisera l'opÃ©rateur strimzi aprÃ¨s l'avoir dÃ©ployÃ©.

## PrÃ©requis

Vous devez avoir accÃ¨s Ã  un cluster Kubernetes sur votre poste de dÃ©veloppement. Dans le cadre de cet article nous allons utiliser K3d, mais vous pouvez de mÃªme utiliser [Kind](https://kind.sigs.k8s.io/) ou [Minikube](https://kubernetes.io/fr/docs/setup/learning-environment/minikube/).

Vous devez aussi avoir les connaissances de base autour de la crÃ©ation de Chart Helm.

## Ajout de la registry de chart helm strimzi

Dans un terminal lancer la commande suivante:

```bash
helm repo add strimzi https://strimzi.io/charts/
```

Vous pouvez vÃ©rifier que la registry a bien Ã©tÃ© ajoutÃ©e en lanÃ§ant la commande suivante:

```bash
helm repo list
```

qui doit vous donner le rÃ©sultat suivant:

![Helm repo list](/blog/images/post/2020/03/2020-03-30-installation-kafka-strimzi-kubernetes-1.png)

## CrÃ©ation du squelette de notre Chart

Dans un terminal lancer la commande suivante afin de crÃ©er le squelette de notre chart:

```bash
helm3 create kafka
```

Vous devez obtenir l'arborescence suivante, qui correspond Ã  un chart de base:

```bash
ğŸ“¦kafka
 â”£ ğŸ“‚charts
 â”£ ğŸ“‚templates
 â”ƒ â”£ ğŸ“‚tests
 â”ƒ â”ƒ â”— ğŸ“œtest-connection.yaml
 â”ƒ â”£ ğŸ“œNOTES.txt
 â”ƒ â”£ ğŸ“œ_helpers.tpl
 â”ƒ â”£ ğŸ“œdeployment.yaml
 â”ƒ â”£ ğŸ“œhpa.yaml
 â”ƒ â”£ ğŸ“œingress.yaml
 â”ƒ â”£ ğŸ“œservice.yaml
 â”ƒ â”— ğŸ“œserviceaccount.yaml
 â”£ ğŸ“œ.helmignore
 â”£ ğŸ“œChart.yaml
 â”— ğŸ“œvalues.yaml
```

Supprimer les fichiers inutiles, car nous n'avons pas besoin de dÃ©ployment, hpa, ingress, service ou encore service account. AprÃ¨s l'Ã©tape de nettoyage, notre chart correspond Ã  ceci:

```bash
ğŸ“¦kafka
 â”£ ğŸ“‚charts
 â”£ ğŸ“‚templates
 â”ƒ â”£ ğŸ“‚tests
 â”ƒ â”— ğŸ“œ_helpers.tpl
 â”£ ğŸ“œ.helmignore
 â”£ ğŸ“œChart.yaml
 â”— ğŸ“œvalues.yaml
```

## Ajout de la dÃ©pendance au chart de l'opÃ©rateur Strimzi

Comme dit plus haut, le dÃ©ploiement de l'opÃ©rateur Strimzi (en rÃ©alitÃ© des opÃ©rateurs) peut se faire Ã  l'aide d'un chart Helm. Nous allons donc utiliser le mÃ©canisme de dÃ©pendance de chart pour forcer l'installation de l'opÃ©rateur avant le dÃ©ploiement de notre chart.

Dans le fichier Chart.yaml, ajouter le contenu suivant:

```yaml
dependencies:
- name: strimzi-kafka-operator
  version: "0.21.1"
  repository: "https://strimzi.io/charts/"
```

## DÃ©claration du Kafka cluster, du topic et du Kafka bridge

### Ã‰dition de votre fichier values.yaml

Remplacer le contenu de votre fichier Values.yaml par le contenu suivant:

```yaml
serviceAccount:
  create: true
  annotations: {}
  name: "kafka-cluster-serviceaccount"

kafka:
  name: 'Kafka-cluster'
  replicas: 3
  config:
    offsets:
      topic:
        replication:
          factor: 3
    transaction:
      state:
        log:
          replication:
            factor: 3
          min:
            isr: 2
  storage:
    volume:
      size: 1Mi

zookeeper:
  replicas: 3
  storage:
    size: 1Mi

topic:
  partitions: 3
  replicas: 3
  retention:
    ms: 7200000
  segment:
    bytes: 1073741824
  topics:
  - name: 'topictest'

kafkaMonitoring:
  enabled: true

prometheus-kafka-exporter:
  image:
    repository: "danielqsj/Kafka-exporter"
```

### CrÃ©ation du Kafka cluster

CrÃ©Ã© un fichier kafkacluster.yaml dans le dossier template de votre chart avec le contenu suivant:

```yaml
{% raw %}
---
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: {{ .Values.kafka.name }}
spec:
  kafka:
    version: 2.6.0
    replicas: {{ .Values.kafka.replicas }}
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      offsets.topic.replication.factor: {{ .Values.kafka.config.offsets.topic.replication.factor }}
      transaction.state.log.replication.factor: {{ .Values.kafka.config.transaction.state.log.replication.factor }}
      transaction.state.log.min.isr: {{ .Values.kafka.config.transaction.state.log.min.isr }}
      log.message.format.version: "2.6"
      inter.broker.protocol.version: "2.6"
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: {{ .Values.kafka.storage.volume.size }}
        deleteClaim: false
  zookeeper:
    replicas: {{ .Values.zookeeper.replicas }}
    storage:
      type: persistent-claim
      size: {{ .Values.zookeeper.storage.size }}
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
{% endraw %}
```

### CrÃ©ation du topic

CrÃ©er un fichier kafkatopic.yaml dans le dossier template de votre chart avec le contenu suivan

```yaml
{% raw %}
{{- $root := . -}}
{{- range $.Values.topic.topics }}
---
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: {{ .name | lower | quote }}
  labels:
    strimzi.io/cluster: {{ $root.Values.kafka.name }}
spec:
  partitions: {{ $root.Values.topic.partitions }}
  replicas: {{ $root.Values.topic.replicas }}
  config:
    retention.ms:  {{ $root.Values.topic.retention.ms }}
    segment.bytes:  {{ $root.Values.topic.segment.bytes }}
{{- end}}
{% endraw %}
```

Ce fichier va looper sur la variable du topic.topics du fichier de value pour demander la crÃ©ation de notre topic.

### CrÃ©ation du Kafka bridge

Dans le dossier template de votre chart crÃ©Ã© un fichier kafkabridge.yaml et positionner le contenu suivant:

```yaml
{% raw %}
---
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaBridge
metadata:
  name:  {{ .Values.kafka.name }}-bridge
spec:
  replicas: 1
  bootstrapServers:  {{ .Values.kafka.name }}-kafka-bootstrap:9092
  http:
    port: 8080
{% endraw %}
```

### Mise Ã  jour des dÃ©pendances de chart

Avant de dÃ©ployer votre chart il convient de mettre Ã  jour les dependances de ce dernier. Pour cela lancer la commande suivante dans un terminal:

```bash
helm dependency update ./Kafka/
```

Vous devez obtenir le rÃ©sultat suivant:

![helm repository update](/blog/images/post/2020/03/2020-03-30-installation-kafka-strimzi-kubernetes-2.png)

Cette commande a pour effet de tÃ©lÃ©charger le chart le dossier /charts de votre Chart.

## installation de votre chart et rÃ©sultat

Pour installer votre chart lancer la commande suivante:

```bash
helm install -n Kafka Kafka ./Kafka/ --create-namespace
```

AprÃ¨s quelques minutes vous constaterez dans votre cluster que l'ensemble des Pods Kafka sont lÃ :

1. l'opÃ©rateur strimzi
2. le cluster zookeeper dÃ©diÃ© Ã  l'infrastructure kakfa
3. le cluster Kafka lui-mÃªme
4. le pod pour le bridge Kafka

![resultat installation kafka](/blog/images/post/2020/03/2020-03-30-installation-kafka-strimzi-kubernetes-3.png)

et que les customs ressources de l'opÃ©rateur strimzi sont prÃ©sentes:

![custom ressource strimzi](/blog/images/post/2020/03/2020-03-30-installation-kafka-strimzi-kubernetes-4.png)

Pour avoir accÃ¨s au code source de cet exemple, c'est par ici [https://github.com/matthieupetite/helm-samples](https://github.com/matthieupetite/helm-samples)